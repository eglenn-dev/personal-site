import Image from "next/image";

# Prompt Engineering for Perfect Resumes

### What I learned building [Resumly.pro](https://Resumly.pro)

_2025-07-08_

If you missed my last post on [Resumly.pro](https://Resumly.pro) launch, check it out [here](/blog/resumly-launch).

<Image
    src="/blog/prompt-engineering.png"
    alt="AI generated image of person making resume"
    height={400}
    width={600}
    className="mx-auto mb-4 rounded-lg"
/>

<p className="text-zinc-400 text-sm text-center">Image generated by AI</p>

## The Blank Page and the AI Co-Pilot

Crafting the perfect resume is a universal struggle. Especially when you're not sure what experience to include or how to present it. Enter Resumly.pro, my senior capstone project, which uses Google's Gemini to tackle this challenge head-on. I built an AI resume builder that scans a job application, extracts key requirements, and generates a tailored resume in seconds.

Resumly.pro is a full-stack web application made with React (w/ Next.js), TypeScript, and Tailwind CSS for the frontend, and a Python Flask backend that integrates with the Gemini API and web scraping.

Simply connecting AI isn't enough. The real challenge was figuring out _how_ to ask the AI for what I wanted. This is the art and science of prompt engineering. In this post, I'll show you the evolution of my methodology, from its beginnings to a refined instruction that gets powerful, and professional results.

## What is Prompt Engineering?

Before we dive in, I wanted to clarify what I mean by "prompt engineering."

In my studies and my degree emphasis in Computer Science and Machine Learning, I have build what I like to call a _GPT-1_. It was a very basic GPT model that was trained on a few books from a single author. It was a fun project, but it was nothing compared to the power of modern AI like Gemini 2.5 Pro/Flash models. In building my _GPT-1_ I learned that LLMs are not magic, but a lot of math, and linear algebra. A popular programming YouTuber described them as a _Word Calculator_. You give it prompt (input) and it gives you a likely response (output) based on the patterns it learned from the training data.

The problem with this is that the patterns it learned are not always what you want, or it is very average. Because LLMs are a kind of statistical model, they will give you the most likely response based on the patterns it learned. If we look at a normal distribution, the most likely response is the mean. But we don't always want the mean, we want the best response. This is where prompt engineering comes in.

My ML Professor, Adam Hayes, always said "Garbage in, garbage out."

Prompt engineering is the process of crafting the input to an LLM in a way that guides it to produce the desired output. It's about understanding how the model works and how to leverage its strengths while mitigating its weaknesses. This involves experimenting with different phrasings, structures, and contexts to find the most effective way to communicate your intent.

## Defining the Goal

This first step is defining the goal for the LLM and what you want it to achieve. I have found it best to state the role and mission at the very start of the prompt. Here is an example from one of Resumly.pro's prompts:

```
Role: You are an elite Resume Strategist and Career Storytelling Expert with deep understanding of applicant tracking systems (ATS) and hiring psychology.

Mission: Craft a compelling, strategically optimized resume that positions the candidate as the ideal fit for their target role while authentically representing their professional journey.
```

After defining the role and mission I define what a good resume bullet point looks like. I originally was going to provide examples, but because of the vast number of different roles and industries, I found it best to define the characteristics of a good bullet point. Here is an example:

```
Transform descriptions using the IMPACT Method:

- Initiate with powerful action verbs (Led, Architected, Optimized, Pioneered)
- Measure outcomes with quantifiable results when possible
- Position achievements within business context
- Align language with target role requirements
- Create compelling narratives that demonstrate growth
- Tailor messaging to resonate with hiring managers
```

I found that this, along with the rest of the prompt, provided enough context for the LLM to understand what I wanted it to do. It also allowed me to easily change the characteristics of a good bullet point without having to rewrite the entire prompt.

## Allowing the LLM to be Creative

One important aspect of this project, was I did not want the LLM to fabricate information. Instead, I wanted it to use the information it had been trained on to generate creative and relevant responses. This meant providing it with enough context and guidance to understand the boundaries of the task while still allowing for creative expression.

To achieve this, I provided the LLM with a set of guidelines and constraints, but also encouraged it to think outside the box. For example I gave it instruction to "Elevate language sophistication while maintaining authenticity", "Strategically emphasize accomplishments that mirror job requirements", and "Synthesize related responsibilities into powerful, cohesive statements", among many others.

This helped a lot and was instrumental in guiding the LLM's creative process while keeping it anchored to the task at hand, and preventing it from going off the rails and making up false information about the user. Additionally, avoiding specific language like "do not fabricate" or "do not lie" helped the LLM to focus on the task without feeling constrained by negative instructions.

## From Asking to Requiring JSON

Initially when I had started working on this
